import time
import re
import random
import gc
import traceback
from PyQt6.QtCore import QThread, pyqtSignal

try:
    import undetected_chromedriver as uc
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, NoSuchElementException
    UC_AVAILABLE = True
except ImportError:
    UC_AVAILABLE = False

try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
except ImportError:
    BS4_AVAILABLE = False

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

from src.utils.constants import CRAWL_SPEED_PRESETS
from src.utils.helpers import AreaConverter, PriceConverter, PricePerPyeongCalculator, DateTimeHelper, ChromeParamHelper
from src.utils.logger import get_logger
from src.utils.retry_handler import RetryHandler
from src.core.item_parser import ItemParser

# ë©”ëª¨ë¦¬ ì„ê³„ì¹˜ (MB) - ì´ˆê³¼ ì‹œ ë“œë¼ì´ë²„ ì¬ì‹œì‘
MEMORY_THRESHOLD_MB = 500

class CrawlerThread(QThread):
    log_signal = pyqtSignal(str, int)
    progress_signal = pyqtSignal(int, str, int)  # percent, current_name, remaining_seconds
    item_signal = pyqtSignal(dict)
    stats_signal = pyqtSignal(dict)
    complex_finished_signal = pyqtSignal(str, str, str, int)
    finished_signal = pyqtSignal(list)
    error_signal = pyqtSignal(str)
    alert_triggered_signal = pyqtSignal(str, str, str, float, int)
    
    def __init__(self, targets, trade_types, area_filter, price_filter, db, speed="ë³´í†µ", cache=None):
        super().__init__()
        self.targets = targets
        self.trade_types = trade_types
        self.area_filter = area_filter
        self.price_filter = price_filter
        self.db = db
        self.speed = speed
        self.cache = cache  # v12.0: CrawlCache ì¸ìŠ¤í„´ìŠ¤
        self._running = True
        self.collected_data = []
        self.stats = {"total_found": 0, "filtered_out": 0, "cache_hits": 0, "by_trade_type": {"ë§¤ë§¤": 0, "ì „ì„¸": 0, "ì›”ì„¸": 0}}
        self.start_time = None
        self.items_per_second = 0
        self.retry_handler = RetryHandler()
    
    def stop(self): self._running = False
    def log(self, msg, level=20): self.log_signal.emit(msg, level)
    
    def _init_driver(self):
        """Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” ë° ì„¤ì •"""
        
        # Chrome ë²„ì „ ìë™ ê°ì§€
        detected_version = ChromeParamHelper.get_chrome_major_version()
        version_msg = f" (ê°ì§€ëœ ë²„ì „: {detected_version})" if detected_version else " (ë²„ì „ ìë™ ê°ì§€)"
        self.log(f"ğŸ”§ Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì¤‘...{version_msg}")
        
        options = uc.ChromeOptions()
        options.add_argument("--headless=new")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        options.add_argument("--disable-software-rasterizer")
        options.add_argument("--window-size=1920,1080")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
        options.add_argument("--log-level=3")
        
        driver = None
        try:
            # ê°ì§€ëœ ë²„ì „ì´ ìˆìœ¼ë©´ í•´ë‹¹ ë²„ì „ ì‚¬ìš©, ì—†ìœ¼ë©´ None (ìµœì‹ /ìë™)
            driver = uc.Chrome(options=options, version_main=detected_version)
            self.log("âœ… Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            self.log(f"âš ï¸ Headless ì‹¤íŒ¨, ì¼ë°˜ ëª¨ë“œ ì‹œë„... ({e})", 30)
            options2 = uc.ChromeOptions()
            options2.add_argument("--no-sandbox")
            options2.add_argument("--disable-dev-shm-usage")
            options2.add_argument("--disable-gpu")
            options2.add_argument("--window-size=1920,1080")
            options2.add_argument("--start-minimized")
            driver = uc.Chrome(options=options2, version_main=detected_version)
            self.log("âœ… Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì„±ê³µ (ì¼ë°˜ ëª¨ë“œ)")
        
        if driver:
            driver.set_page_load_timeout(30)
            driver.implicitly_wait(5)
            
        return driver

    def run(self):
        if not UC_AVAILABLE or not BS4_AVAILABLE:
            self.error_signal.emit("í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜\npip install undetected-chromedriver beautifulsoup4")
            return
            
        driver = None
        self.start_time = time.time()
        
        try:
            self.log("ğŸš€ í¬ë¡¤ë§ ì‹œì‘...")
            driver = self._init_driver()
            if not driver:
                raise Exception("ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            total = len(self.targets) * len(self.trade_types)
            current = 0
            processed_complexes = 0  # ì²˜ë¦¬í•œ ë‹¨ì§€ ìˆ˜
            
            for name, cid in self.targets:
                if not self._running: break
                
                # v14.0: ë©”ëª¨ë¦¬ ê¸°ë°˜ ë“œë¼ì´ë²„ ì¬ì‹œì‘ (500MB ì„ê³„ì¹˜)
                should_restart = False
                if PSUTIL_AVAILABLE:
                    memory_mb = psutil.Process().memory_info().rss / (1024 * 1024)
                    if memory_mb > MEMORY_THRESHOLD_MB:
                        should_restart = True
                        self.log(f"ğŸ”„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ {memory_mb:.0f}MB ì´ˆê³¼, ë“œë¼ì´ë²„ ì¬ì‹œì‘...")
                else:
                    # psutil ë¯¸ì„¤ì¹˜ ì‹œ ê¸°ì¡´ ë°©ì‹ (3ë‹¨ì§€ë§ˆë‹¤)
                    if processed_complexes > 0 and processed_complexes % 3 == 0:
                        should_restart = True
                        self.log("ğŸ”„ Chrome ë“œë¼ì´ë²„ ì¬ì‹œì‘ (ë©”ëª¨ë¦¬ ì •ë¦¬)...")
                
                if should_restart:
                    try:
                        driver.quit()
                    except Exception as e:
                        self.log(f"âš ï¸ ë“œë¼ì´ë²„ ì¢…ë£Œ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}", 30)
                    driver = None
                    gc.collect()
                    time.sleep(1)
                    
                    driver = self._init_driver()
                    if not driver:
                        raise Exception("ë“œë¼ì´ë²„ ì¬ì‹œì‘ ì‹¤íŒ¨")
                
                complex_count = 0
                for ttype in self.trade_types:
                    if not self._running: break
                    current += 1
                    
                    # ì˜ˆìƒ ë‚¨ì€ ì‹œê°„ ê³„ì‚°
                    elapsed = time.time() - self.start_time
                    avg_time = elapsed / current if current > 0 else 5
                    remaining = int(avg_time * (total - current))
                    
                    self.progress_signal.emit(int(current / total * 100), f"{name} ({ttype})", remaining)
                    self.log(f"\\nğŸ“ [{current}/{total}] {name} - {ttype}")
                    
                    try:
                        count = self._crawl(driver, name, cid, ttype)
                        complex_count += count
                        self.stats["by_trade_type"][ttype] = self.stats["by_trade_type"].get(ttype, 0) + count
                        self.log(f"   âœ… {count}ê±´ ìˆ˜ì§‘")
                    except Exception as e:
                        self.log(f"   âŒ ì˜¤ë¥˜: {e}", 40)
                        self.log(f"   ìƒì„¸: {traceback.format_exc()}", 40)
                        
                        # ì¹˜ëª…ì  ì˜¤ë¥˜(ì„¸ì…˜ ì¢…ë£Œ ë“±) ë°œìƒ ì‹œ ë“œë¼ì´ë²„ ì¬ì‹œì‘ ì‹œë„
                        if "SessionNotCreatedException" in str(e) or "NoSuchWindowException" in str(e) or "WebDriverException" in str(e):
                             self.log("âš ï¸ ë“œë¼ì´ë²„ ì„¸ì…˜ ì˜¤ë¥˜ ê°ì§€, ì¬ì‹œì‘ ì‹œë„...", 30)
                             try:
                                 driver.quit()
                             except Exception as quit_err:
                                 self.log(f"âš ï¸ ë“œë¼ì´ë²„ ì¢…ë£Œ ì‹¤íŒ¨ (ë¬´ì‹œ): {quit_err}", 30)
                             driver = self._init_driver()
                    
                    speed_cfg = CRAWL_SPEED_PRESETS.get(self.speed, CRAWL_SPEED_PRESETS["ë³´í†µ"])
                    time.sleep(random.uniform(speed_cfg["min"], speed_cfg["max"]))
                
                self.complex_finished_signal.emit(name, cid, ",".join(self.trade_types), complex_count)
                processed_complexes += 1
            
            self.log(f"\\n{'='*50}\\nâœ… ì™„ë£Œ! ì´ {len(self.collected_data)}ê±´")
        except Exception as e:
            self.log(f"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}", 40)
            self.log(f"ìƒì„¸:\\n{traceback.format_exc()}", 40)
            self.error_signal.emit(str(e))
        finally:
            if driver:
                try:
                    driver.quit()
                    self.log("âœ… Chrome ë“œë¼ì´ë²„ ì¢…ë£Œ ì™„ë£Œ")
                except Exception as e:
                    self.log(f"âš ï¸ Chrome ë“œë¼ì´ë²„ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}", 30)
            self.finished_signal.emit(self.collected_data)
    
    def _crawl(self, driver, name, cid, ttype):
        # v12.0: ìºì‹œ í™•ì¸
        if self.cache:
            cached_items = self.cache.get(cid, ttype)
            if cached_items:
                self.log(f"   ğŸ’¾ ìºì‹œ íˆíŠ¸! {len(cached_items)}ê±´ ë¡œë“œ")
                self.stats["cache_hits"] = self.stats.get("cache_hits", 0) + 1
                # ìºì‹œëœ ì•„ì´í…œì„ collected_dataì— ì¶”ê°€í•˜ê³  ì‹œê·¸ë„ ë°œì†¡
                for item in cached_items:
                    if self._check_filters(item, ttype):
                        self.collected_data.append(item)
                        self.item_signal.emit(item)
                        self.stats["total_found"] += 1
                    else:
                        self.stats["filtered_out"] += 1
                self.stats_signal.emit(self.stats)
                return len([i for i in cached_items if self._check_filters(i, ttype)])
        
        trade_param = {"ë§¤ë§¤": "A1", "ì „ì„¸": "B1", "ì›”ì„¸": "B2"}.get(ttype, "A1")
        url = f"https://new.land.naver.com/complexes/{cid}?ms=37.5,127,16&a=APT&e=RETAIL&tradeTypes={trade_param}"
        
        self.log(f"   ğŸ”— URL ì ‘ì† ì¤‘...")
        try:
            self.retry_handler.execute_with_retry(driver.get, url)
        except Exception as e:
            self.log(f"   âŒ URL ì ‘ì† ì‹¤íŒ¨: {e}", 40)
            return 0
        
        # v14.0: ë™ì  ëŒ€ê¸° - í˜ì´ì§€ ë¡œë“œ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located(("css selector", ".article_list, .item_list, .complex_list, [class*='article']"))
            )
        except TimeoutException:
            self.log("   âš ï¸ ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼, ê³„ì† ì§„í–‰...", 30)
        
        try:
            article_tab = driver.find_element("css selector", "a[href*='articleList'], .tab_item[data-tab='article']")
            article_tab.click()
            # v14.0: íƒ­ í´ë¦­ í›„ ë™ì  ëŒ€ê¸°
            try:
                WebDriverWait(driver, 5).until(
                    EC.presence_of_element_located(("css selector", ".item_article, .item_inner"))
                )
            except TimeoutException:
                self.log("   â„¹ï¸ ë§¤ë¬¼ íƒ­ ë¡œë“œ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ (ë¬´ì‹œ)", 10)
        except (NoSuchElementException, Exception) as e:
            # íƒ­ í´ë¦­ ì‹¤íŒ¨ëŠ” ì •ìƒì ì¸ ìƒí™©ì¼ ìˆ˜ ìˆìŒ (íƒ­ì´ ì—†ëŠ” ê²½ìš°)
            self.log(f"   â„¹ï¸ ë§¤ë¬¼ íƒ­ ì°¾ê¸° ì‹¤íŒ¨ (ì •ìƒ): {type(e).__name__}", 10)
        
        self._scroll(driver)
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        count = self._parse(soup, name, cid, ttype)
        
        # v12.0: í¬ë¡¤ë§ ê²°ê³¼ ìºì‹œ ì €ì¥
        if self.cache and count > 0:
            # ì´ ë‹¨ì§€+ê±°ë˜ìœ í˜•ì˜ ì•„ì´í…œë§Œ í•„í„°ë§í•´ì„œ ìºì‹œ
            items_to_cache = [
                d for d in self.collected_data 
                if d.get("ë‹¨ì§€ID") == cid and d.get("ê±°ë˜ìœ í˜•") == ttype
            ]
            if items_to_cache:
                self.cache.set(cid, ttype, items_to_cache)
        
        return count
    
    def _scroll(self, driver):
        """v14.0: ì»¨í…ì¸  ë³€í™” ê°ì§€ ê¸°ë°˜ ìµœì í™”ëœ ìŠ¤í¬ë¡¤"""
        try:
            # ì»¨í…ì¸  ì•„ì´í…œ ìˆ˜ ê¸°ë°˜ ìŠ¤í¬ë¡¤ (ë” íš¨ìœ¨ì )
            selectors = ".item_article, .item_inner, .article_item, [class*='ArticleItem']"
            last_count = 0
            stable_count = 0
            max_scroll_attempts = 15  # ìµœëŒ€ ìŠ¤í¬ë¡¤ íšŸìˆ˜
            
            for _ in range(max_scroll_attempts):
                if not self._running:
                    break
                
                # í˜„ì¬ ì•„ì´í…œ ìˆ˜ í™•ì¸
                try:
                    items = driver.find_elements("css selector", selectors)
                    current_count = len(items)
                except Exception:
                    current_count = 0
                
                # ì•„ì´í…œ ìˆ˜ê°€ ë³€í•˜ì§€ ì•Šìœ¼ë©´ ì¹´ìš´íŠ¸ ì¦ê°€
                if current_count == last_count:
                    stable_count += 1
                    if stable_count >= 2:  # 2ë²ˆ ì—°ì† ë³€í™” ì—†ìœ¼ë©´ ì¢…ë£Œ
                        break
                else:
                    stable_count = 0
                    last_count = current_count
                
                # ìŠ¤í¬ë¡¤ ì‹¤í–‰
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight)")
                time.sleep(0.8)  # ìµœì†Œ ëŒ€ê¸° (ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì‹œê°„ ê³ ë ¤)
                
        except Exception as e:
            self.log(f"   âš ï¸ ìŠ¤í¬ë¡¤ ì˜¤ë¥˜: {e}", 30)
    
    def _parse(self, soup, name, cid, ttype):
        items = []
        found_items = ItemParser.find_items(soup)
        
        if found_items:
            # ì„ íƒì ë¡œê¹… (ItemParser ë‚´ë¶€ ë””ë²„ê·¸ ë¡œê·¸ì™€ ë³„ê°œë¡œ ì‚¬ìš©ìì—ê²Œ ì§„í–‰ìƒí™© í‘œì‹œ)
            self.log(f"   ğŸ” íŒŒì‹± ëŒ€ìƒ: {len(found_items)}ê°œ")
        else:
            self.log("   âš ï¸ íŒŒì‹± ëŒ€ìƒ í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", 10)
            return 0
        
        matched_count, skipped_type = 0, 0
        
        for item in found_items:
            if not self._running: break
            try:
                data = ItemParser.parse_element(item, name, cid, ttype)
                if data and data.get("ë©´ì (ã¡)", 0) > 0:
                    detected_type = data.get("ê±°ë˜ìœ í˜•", "")
                    if detected_type == ttype:
                        if self._check_filters(data, ttype):
                            self.collected_data.append(data)
                            self.item_signal.emit(data)
                            items.append(data)
                            self.stats["total_found"] += 1
                            matched_count += 1
                        else:
                            self.stats["filtered_out"] += 1
                        self.stats_signal.emit(self.stats)
                    else:
                        skipped_type += 1
            except Exception as e:
                self.log(f"   âš ï¸ í•­ëª© íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}", 30)
        
        if skipped_type > 0:
            self.log(f"   â„¹ï¸ ë‹¤ë¥¸ ê±°ë˜ìœ í˜• {skipped_type}ê±´ ì œì™¸ (ìš”ì²­: {ttype})")
        
        return matched_count

        
    def _check_filters(self, data, ttype):
        if self.area_filter.get("enabled"):
            sqm = data.get("ë©´ì (ã¡)", 0)
            if sqm < self.area_filter.get("min", 0) or sqm > self.area_filter.get("max", 999):
                return False
        if self.price_filter.get("enabled"):
            price_range = self.price_filter.get(ttype, {})
            min_p, max_p = price_range.get("min", 0), price_range.get("max", 999999)
            if ttype == "ë§¤ë§¤": price = PriceConverter.to_int(data.get("ë§¤ë§¤ê°€", "0"))
            else: price = PriceConverter.to_int(data.get("ë³´ì¦ê¸ˆ", "0"))
            if price < min_p or price > max_p: return False
        return True
