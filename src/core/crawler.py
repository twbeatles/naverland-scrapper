import time
import re
import random
import gc
import traceback
from PyQt6.QtCore import QThread, pyqtSignal

try:
    import undetected_chromedriver as uc
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, NoSuchElementException
    UC_AVAILABLE = True
except ImportError:
    UC_AVAILABLE = False

try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
except ImportError:
    BS4_AVAILABLE = False

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

from src.utils.constants import CRAWL_SPEED_PRESETS
from src.utils.helpers import AreaConverter, PriceConverter, PricePerPyeongCalculator, DateTimeHelper, ChromeParamHelper
from src.utils.logger import get_logger
from src.utils.retry_handler import RetryHandler
<<<<<<< HEAD
from src.core.item_parser import ItemParser
=======
>>>>>>> 39500298f217e86700ed82ba5199a76ef9100859

# ë©”ëª¨ë¦¬ ì„ê³„ì¹˜ (MB) - ì´ˆê³¼ ì‹œ ë“œë¼ì´ë²„ ì¬ì‹œì‘
MEMORY_THRESHOLD_MB = 500

class CrawlerThread(QThread):
    log_signal = pyqtSignal(str, int)
    progress_signal = pyqtSignal(int, str, int)  # percent, current_name, remaining_seconds
    item_signal = pyqtSignal(dict)
    stats_signal = pyqtSignal(dict)
    complex_finished_signal = pyqtSignal(str, str, str, int)
    finished_signal = pyqtSignal(list)
    error_signal = pyqtSignal(str)
    alert_triggered_signal = pyqtSignal(str, str, str, float, int)
    
    def __init__(self, targets, trade_types, area_filter, price_filter, db, speed="ë³´í†µ", cache=None):
        super().__init__()
        self.targets = targets
        self.trade_types = trade_types
        self.area_filter = area_filter
        self.price_filter = price_filter
        self.db = db
        self.speed = speed
        self.cache = cache  # v12.0: CrawlCache ì¸ìŠ¤í„´ìŠ¤
        self._running = True
        self.collected_data = []
        self.stats = {"total_found": 0, "filtered_out": 0, "cache_hits": 0, "by_trade_type": {"ë§¤ë§¤": 0, "ì „ì„¸": 0, "ì›”ì„¸": 0}}
        self.start_time = None
        self.items_per_second = 0
        self.retry_handler = RetryHandler()
    
    def stop(self): self._running = False
    def log(self, msg, level=20): self.log_signal.emit(msg, level)
    
    def _init_driver(self):
        """Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” ë° ì„¤ì •"""
        
        # Chrome ë²„ì „ ìë™ ê°ì§€
        detected_version = ChromeParamHelper.get_chrome_major_version()
        version_msg = f" (ê°ì§€ëœ ë²„ì „: {detected_version})" if detected_version else " (ë²„ì „ ìë™ ê°ì§€)"
        self.log(f"ğŸ”§ Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì¤‘...{version_msg}")
        
        options = uc.ChromeOptions()
        options.add_argument("--headless=new")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        options.add_argument("--disable-software-rasterizer")
        options.add_argument("--window-size=1920,1080")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
        options.add_argument("--log-level=3")
        
        driver = None
        try:
            # ê°ì§€ëœ ë²„ì „ì´ ìˆìœ¼ë©´ í•´ë‹¹ ë²„ì „ ì‚¬ìš©, ì—†ìœ¼ë©´ None (ìµœì‹ /ìë™)
            driver = uc.Chrome(options=options, version_main=detected_version)
            self.log("âœ… Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            self.log(f"âš ï¸ Headless ì‹¤íŒ¨, ì¼ë°˜ ëª¨ë“œ ì‹œë„... ({e})", 30)
            options2 = uc.ChromeOptions()
            options2.add_argument("--no-sandbox")
            options2.add_argument("--disable-dev-shm-usage")
            options2.add_argument("--disable-gpu")
            options2.add_argument("--window-size=1920,1080")
            options2.add_argument("--start-minimized")
            driver = uc.Chrome(options=options2, version_main=detected_version)
            self.log("âœ… Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì„±ê³µ (ì¼ë°˜ ëª¨ë“œ)")
        
        if driver:
            driver.set_page_load_timeout(30)
            driver.implicitly_wait(5)
            
        return driver

    def run(self):
        if not UC_AVAILABLE or not BS4_AVAILABLE:
            self.error_signal.emit("í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜\npip install undetected-chromedriver beautifulsoup4")
            return
            
        driver = None
        self.start_time = time.time()
        
        try:
            self.log("ğŸš€ í¬ë¡¤ë§ ì‹œì‘...")
            driver = self._init_driver()
            if not driver:
                raise Exception("ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            total = len(self.targets) * len(self.trade_types)
            current = 0
            processed_complexes = 0  # ì²˜ë¦¬í•œ ë‹¨ì§€ ìˆ˜
            
            for name, cid in self.targets:
                if not self._running: break
                
                # v14.0: ë©”ëª¨ë¦¬ ê¸°ë°˜ ë“œë¼ì´ë²„ ì¬ì‹œì‘ (500MB ì„ê³„ì¹˜)
                should_restart = False
                if PSUTIL_AVAILABLE:
                    memory_mb = psutil.Process().memory_info().rss / (1024 * 1024)
                    if memory_mb > MEMORY_THRESHOLD_MB:
                        should_restart = True
                        self.log(f"ğŸ”„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ {memory_mb:.0f}MB ì´ˆê³¼, ë“œë¼ì´ë²„ ì¬ì‹œì‘...")
                else:
                    # psutil ë¯¸ì„¤ì¹˜ ì‹œ ê¸°ì¡´ ë°©ì‹ (3ë‹¨ì§€ë§ˆë‹¤)
                    if processed_complexes > 0 and processed_complexes % 3 == 0:
                        should_restart = True
                        self.log("ğŸ”„ Chrome ë“œë¼ì´ë²„ ì¬ì‹œì‘ (ë©”ëª¨ë¦¬ ì •ë¦¬)...")
                
                if should_restart:
                    try:
                        driver.quit()
                    except Exception as e:
                        self.log(f"âš ï¸ ë“œë¼ì´ë²„ ì¢…ë£Œ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}", 30)
                    driver = None
                    gc.collect()
                    time.sleep(1)
                    
                    driver = self._init_driver()
                    if not driver:
                        raise Exception("ë“œë¼ì´ë²„ ì¬ì‹œì‘ ì‹¤íŒ¨")
                
                complex_count = 0
                for ttype in self.trade_types:
                    if not self._running: break
                    current += 1
                    
                    # ì˜ˆìƒ ë‚¨ì€ ì‹œê°„ ê³„ì‚°
                    elapsed = time.time() - self.start_time
                    avg_time = elapsed / current if current > 0 else 5
                    remaining = int(avg_time * (total - current))
                    
                    self.progress_signal.emit(int(current / total * 100), f"{name} ({ttype})", remaining)
                    self.log(f"\\nğŸ“ [{current}/{total}] {name} - {ttype}")
                    
                    try:
                        count = self._crawl(driver, name, cid, ttype)
                        complex_count += count
                        self.stats["by_trade_type"][ttype] = self.stats["by_trade_type"].get(ttype, 0) + count
                        self.log(f"   âœ… {count}ê±´ ìˆ˜ì§‘")
                    except Exception as e:
                        self.log(f"   âŒ ì˜¤ë¥˜: {e}", 40)
                        self.log(f"   ìƒì„¸: {traceback.format_exc()}", 40)
                        
                        # ì¹˜ëª…ì  ì˜¤ë¥˜(ì„¸ì…˜ ì¢…ë£Œ ë“±) ë°œìƒ ì‹œ ë“œë¼ì´ë²„ ì¬ì‹œì‘ ì‹œë„
                        if "SessionNotCreatedException" in str(e) or "NoSuchWindowException" in str(e) or "WebDriverException" in str(e):
                             self.log("âš ï¸ ë“œë¼ì´ë²„ ì„¸ì…˜ ì˜¤ë¥˜ ê°ì§€, ì¬ì‹œì‘ ì‹œë„...", 30)
                             try:
                                 driver.quit()
                             except Exception as quit_err:
                                 self.log(f"âš ï¸ ë“œë¼ì´ë²„ ì¢…ë£Œ ì‹¤íŒ¨ (ë¬´ì‹œ): {quit_err}", 30)
                             driver = self._init_driver()
                    
                    speed_cfg = CRAWL_SPEED_PRESETS.get(self.speed, CRAWL_SPEED_PRESETS["ë³´í†µ"])
                    time.sleep(random.uniform(speed_cfg["min"], speed_cfg["max"]))
                
                self.complex_finished_signal.emit(name, cid, ",".join(self.trade_types), complex_count)
                processed_complexes += 1
            
            self.log(f"\\n{'='*50}\\nâœ… ì™„ë£Œ! ì´ {len(self.collected_data)}ê±´")
        except Exception as e:
            self.log(f"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}", 40)
            self.log(f"ìƒì„¸:\\n{traceback.format_exc()}", 40)
            self.error_signal.emit(str(e))
        finally:
            if driver:
                try:
                    driver.quit()
                    self.log("âœ… Chrome ë“œë¼ì´ë²„ ì¢…ë£Œ ì™„ë£Œ")
                except Exception as e:
                    self.log(f"âš ï¸ Chrome ë“œë¼ì´ë²„ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}", 30)
            self.finished_signal.emit(self.collected_data)
    
    def _crawl(self, driver, name, cid, ttype):
        # v12.0: ìºì‹œ í™•ì¸
        if self.cache:
            cached_items = self.cache.get(cid, ttype)
            if cached_items:
                self.log(f"   ğŸ’¾ ìºì‹œ íˆíŠ¸! {len(cached_items)}ê±´ ë¡œë“œ")
                self.stats["cache_hits"] = self.stats.get("cache_hits", 0) + 1
                # ìºì‹œëœ ì•„ì´í…œì„ collected_dataì— ì¶”ê°€í•˜ê³  ì‹œê·¸ë„ ë°œì†¡
                for item in cached_items:
                    if self._check_filters(item, ttype):
                        self.collected_data.append(item)
                        self.item_signal.emit(item)
                        self.stats["total_found"] += 1
                    else:
                        self.stats["filtered_out"] += 1
                self.stats_signal.emit(self.stats)
                return len([i for i in cached_items if self._check_filters(i, ttype)])
        
        trade_param = {"ë§¤ë§¤": "A1", "ì „ì„¸": "B1", "ì›”ì„¸": "B2"}.get(ttype, "A1")
        url = f"https://new.land.naver.com/complexes/{cid}?ms=37.5,127,16&a=APT&e=RETAIL&tradeTypes={trade_param}"
        
        self.log(f"   ğŸ”— URL ì ‘ì† ì¤‘...")
        try:
            self.retry_handler.execute_with_retry(driver.get, url)
        except Exception as e:
            self.log(f"   âŒ URL ì ‘ì† ì‹¤íŒ¨: {e}", 40)
            return 0
        
        # v14.0: ë™ì  ëŒ€ê¸° - í˜ì´ì§€ ë¡œë“œ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located(("css selector", ".article_list, .item_list, .complex_list, [class*='article']"))
            )
        except TimeoutException:
            self.log("   âš ï¸ ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼, ê³„ì† ì§„í–‰...", 30)
        
        try:
            article_tab = driver.find_element("css selector", "a[href*='articleList'], .tab_item[data-tab='article']")
            article_tab.click()
            # v14.0: íƒ­ í´ë¦­ í›„ ë™ì  ëŒ€ê¸°
            try:
                WebDriverWait(driver, 5).until(
                    EC.presence_of_element_located(("css selector", ".item_article, .item_inner"))
                )
            except TimeoutException:
                self.log("   â„¹ï¸ ë§¤ë¬¼ íƒ­ ë¡œë“œ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ (ë¬´ì‹œ)", 10)
        except (NoSuchElementException, Exception) as e:
            # íƒ­ í´ë¦­ ì‹¤íŒ¨ëŠ” ì •ìƒì ì¸ ìƒí™©ì¼ ìˆ˜ ìˆìŒ (íƒ­ì´ ì—†ëŠ” ê²½ìš°)
            self.log(f"   â„¹ï¸ ë§¤ë¬¼ íƒ­ ì°¾ê¸° ì‹¤íŒ¨ (ì •ìƒ): {type(e).__name__}", 10)
        
        self._scroll(driver)
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        count = self._parse(soup, name, cid, ttype)
        
        # v12.0: í¬ë¡¤ë§ ê²°ê³¼ ìºì‹œ ì €ì¥
        if self.cache and count > 0:
            # ì´ ë‹¨ì§€+ê±°ë˜ìœ í˜•ì˜ ì•„ì´í…œë§Œ í•„í„°ë§í•´ì„œ ìºì‹œ
            items_to_cache = [
                d for d in self.collected_data 
                if d.get("ë‹¨ì§€ID") == cid and d.get("ê±°ë˜ìœ í˜•") == ttype
            ]
            if items_to_cache:
                self.cache.set(cid, ttype, items_to_cache)
        
        return count
    
    def _scroll(self, driver):
        """v14.0: ì»¨í…ì¸  ë³€í™” ê°ì§€ ê¸°ë°˜ ìµœì í™”ëœ ìŠ¤í¬ë¡¤"""
        try:
            # ì»¨í…ì¸  ì•„ì´í…œ ìˆ˜ ê¸°ë°˜ ìŠ¤í¬ë¡¤ (ë” íš¨ìœ¨ì )
            selectors = ".item_article, .item_inner, .article_item, [class*='ArticleItem']"
            last_count = 0
            stable_count = 0
            max_scroll_attempts = 15  # ìµœëŒ€ ìŠ¤í¬ë¡¤ íšŸìˆ˜
            
            for _ in range(max_scroll_attempts):
                if not self._running:
                    break
                
                # í˜„ì¬ ì•„ì´í…œ ìˆ˜ í™•ì¸
                try:
                    items = driver.find_elements("css selector", selectors)
                    current_count = len(items)
                except Exception:
                    current_count = 0
                
                # ì•„ì´í…œ ìˆ˜ê°€ ë³€í•˜ì§€ ì•Šìœ¼ë©´ ì¹´ìš´íŠ¸ ì¦ê°€
                if current_count == last_count:
                    stable_count += 1
                    if stable_count >= 2:  # 2ë²ˆ ì—°ì† ë³€í™” ì—†ìœ¼ë©´ ì¢…ë£Œ
                        break
                else:
                    stable_count = 0
                    last_count = current_count
                
                # ìŠ¤í¬ë¡¤ ì‹¤í–‰
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight)")
                time.sleep(0.8)  # ìµœì†Œ ëŒ€ê¸° (ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì‹œê°„ ê³ ë ¤)
                
        except Exception as e:
            self.log(f"   âš ï¸ ìŠ¤í¬ë¡¤ ì˜¤ë¥˜: {e}", 30)
    
    def _parse(self, soup, name, cid, ttype):
        items = []
<<<<<<< HEAD
        found_items = ItemParser.find_items(soup)
        
        if found_items:
            # ì„ íƒì ë¡œê¹… (ItemParser ë‚´ë¶€ ë””ë²„ê·¸ ë¡œê·¸ì™€ ë³„ê°œë¡œ ì‚¬ìš©ìì—ê²Œ ì§„í–‰ìƒí™© í‘œì‹œ)
            self.log(f"   ğŸ” íŒŒì‹± ëŒ€ìƒ: {len(found_items)}ê°œ")
        else:
            self.log("   âš ï¸ íŒŒì‹± ëŒ€ìƒ í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", 10)
            return 0
        
        matched_count, skipped_type = 0, 0
        
        for item in found_items:
            if not self._running: break
            try:
                data = ItemParser.parse_element(item, name, cid, ttype)
=======
        article_items = []
        
        for sel in [".item_article", ".item_inner", ".article_item", "[class*='ArticleItem']", ".complex_item", "li[data-article-id]", ".list_item"]:
            found = soup.select(sel)
            if found:
                article_items = found
                self.log(f"   ğŸ“‹ ì„ íƒì '{sel}': {len(found)}ê°œ ë°œê²¬")
                break
        
        if not article_items:
            self.log("   âš ï¸ í‘œì¤€ ì„ íƒì ì‹¤íŒ¨, ëŒ€ì²´ ë°©ì‹ ì‹œë„...")
            article_items = soup.find_all(['div', 'li'], class_=lambda x: x and ('item' in x.lower() or 'article' in x.lower()))
        
        self.log(f"   ğŸ” íŒŒì‹± ëŒ€ìƒ: {len(article_items)}ê°œ")
        
        matched_count, skipped_type = 0, 0
        
        for item in article_items:
            if not self._running: break
            try:
                data = self._parse_item(item, name, cid, ttype)
>>>>>>> 39500298f217e86700ed82ba5199a76ef9100859
                if data and data.get("ë©´ì (ã¡)", 0) > 0:
                    detected_type = data.get("ê±°ë˜ìœ í˜•", "")
                    if detected_type == ttype:
                        if self._check_filters(data, ttype):
                            self.collected_data.append(data)
                            self.item_signal.emit(data)
                            items.append(data)
                            self.stats["total_found"] += 1
                            matched_count += 1
                        else:
                            self.stats["filtered_out"] += 1
                        self.stats_signal.emit(self.stats)
                    else:
                        skipped_type += 1
            except Exception as e:
                self.log(f"   âš ï¸ í•­ëª© íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}", 30)
        
        if skipped_type > 0:
            self.log(f"   â„¹ï¸ ë‹¤ë¥¸ ê±°ë˜ìœ í˜• {skipped_type}ê±´ ì œì™¸ (ìš”ì²­: {ttype})")
        
        return matched_count
<<<<<<< HEAD

=======
    
    def _parse_item(self, item, name, cid, ttype):
        full_text = item.get_text(separator=" ", strip=True)
        detected_type = ttype
        
        for sel in [".type", ".trade_type", "[class*='type']", ".item_type", ".article_type"]:
            elem = item.select_one(sel)
            if elem:
                type_text = elem.get_text(strip=True)
                if "ë§¤ë§¤" in type_text: detected_type = "ë§¤ë§¤"
                elif "ì „ì„¸" in type_text: detected_type = "ì „ì„¸"
                elif "ì›”ì„¸" in type_text: detected_type = "ì›”ì„¸"
                break
        
        price_text = ""
        for sel in [".item_price strong", ".price_line", ".article_price", "[class*='price']", ".selling_price", ".trade_price", "strong[class*='Price']", ".price"]:
            elem = item.select_one(sel)
            if elem:
                price_text = elem.get_text(strip=True)
                if price_text and ("ì–µ" in price_text or "ë§Œ" in price_text or price_text.replace(",", "").replace("/", "").isdigit()):
                    break
        
        if not price_text:
            price_match = re.search(r'(\d+ì–µ\s*\d*,?\d*ë§Œ?|\d+,?\d*ë§Œ)', full_text)
            if price_match: price_text = price_match.group(1)
        
        if re.search(r'\d+[ì–µë§Œ]?\s*/\s*\d+', price_text): detected_type = "ì›”ì„¸"
        elif "ì „ì„¸" in full_text[:50]: detected_type = "ì „ì„¸"
        elif "ë§¤ë§¤" in full_text[:50]: detected_type = "ë§¤ë§¤"
        
        area_text, sqm, pyeong = "", 0, 0
        for sel in [".item_area", ".info_area", ".article_area", "[class*='area']"]:
            elem = item.select_one(sel)
            if elem: area_text = elem.get_text(strip=True); break
        if not area_text: area_text = full_text
        
        sqm_match = re.search(r'(\d+(?:\.\d+)?)\s*(?:ã¡|mÂ²)', area_text)
        if sqm_match:
            sqm = float(sqm_match.group(1))
            pyeong = AreaConverter.sqm_to_pyeong(sqm)
        else:
            pyeong_match = re.search(r'(\d+(?:\.\d+)?)\s*í‰', area_text)
            if pyeong_match:
                pyeong = float(pyeong_match.group(1))
                sqm = round(pyeong / 0.3025, 2)
        
        supply_match = re.search(r'(\d+(?:\.\d+)?)[ã¡mÂ²]?\s*/\s*(\d+(?:\.\d+)?)', area_text)
        if supply_match:
            sqm = float(supply_match.group(2))
            pyeong = AreaConverter.sqm_to_pyeong(sqm)
        
        # ì¸µ/ë°©í–¥ ì¶”ì¶œ
        floor_text = ""
        floor_selectors = [
            ".item_floor", ".info_floor", ".floor", "[class*='floor']",
            ".article_floor", ".item_info .floor", "span.floor",
            ".info_article_floor", ".cell_floor", ".data_floor",
            "td.floor", ".item_cell.floor", "[class*='Floor']"
        ]
        for sel in floor_selectors:
            elem = item.select_one(sel)
            if elem:
                floor_text = elem.get_text(strip=True)
                if floor_text:
                    break
        
        if not floor_text:
            level_match = re.search(r'(ê³ ì¸µ|ì¤‘ì¸µ|ì €ì¸µ)', full_text)
            floor_match = re.search(r'(\d+)\s*ì¸µ', full_text)
            floor_total_match = re.search(r'(\d+)\s*/\s*(\d+)\s*ì¸µ', full_text)
            
            if floor_total_match:
                floor_text = f"{floor_total_match.group(1)}/{floor_total_match.group(2)}ì¸µ"
            elif floor_match:
                floor_text = f"{floor_match.group(1)}ì¸µ"
            elif level_match:
                floor_text = level_match.group(1)
        
        direction = ""
        direction_selectors = [
            ".item_direction", ".direction", "[class*='direction']",
            ".info_direction", ".cell_direction", "[class*='Direction']"
        ]
        for sel in direction_selectors:
            elem = item.select_one(sel)
            if elem:
                direction = elem.get_text(strip=True)
                if direction:
                    break
        
        if not direction:
            dir_match = re.search(r'(ë™í–¥|ì„œí–¥|ë‚¨í–¥|ë¶í–¥|ë‚¨ë™í–¥|ë‚¨ì„œí–¥|ë¶ë™í–¥|ë¶ì„œí–¥|ë™ë‚¨í–¥|ë™ë¶í–¥|ì„œë‚¨í–¥|ì„œë¶í–¥)', full_text)
            if dir_match:
                direction = dir_match.group(1)
        
        if floor_text and direction:
            floor_text = f"{floor_text} {direction}"
        elif direction and not floor_text:
            floor_text = direction
        
        feature_text = ""
        ad_keywords = [
            "ë¶€ë™ì‚°ë±…í¬", "ì§ë°©", "ë‹¤ë°©", "í”¼í„°íŒ¬", "ë„¤ì´ë²„ë¶€ë™ì‚°", "KBë¶€ë™ì‚°",
            "ë¶€ë™ì‚°114", "í˜¸ê°±ë…¸ë…¸", "ë§¤ë¬¼ë²ˆí˜¸", "ì¤‘ê°œì‚¬ë¬´ì†Œ", "ê³µì¸ì¤‘ê°œì‚¬",
            "ì œê³µ", "ì¶œì²˜", "ë¬¸ì˜", "ì—°ë½", "ì „í™”", "ìƒë‹´", "í´ë¦­", "ë°”ë¡œê°€ê¸°",
            "ë”ë³´ê¸°", "ìì„¸íˆ", "í™•ì¸í•˜ì„¸ìš”", "ë“œë¦½ë‹ˆë‹¤", "í•´ë“œë¦½ë‹ˆë‹¤"
        ]
        meaningful_keywords = [
            "ê¸‰ë§¤", "ê¸‰ì „", "ê¸‰ì²˜ë¶„", "ë„¤ê³ ê°€ëŠ¥", "í˜‘ì˜ê°€ëŠ¥", "ê°€ê²©ì¡°ì •", "ì‹¤ë§¤ë¬¼",
            "ì˜¬ìˆ˜ë¦¬", "í’€ìˆ˜ë¦¬", "ë¦¬ëª¨ë¸ë§", "ì¸í…Œë¦¬ì–´", "í’€ì˜µì…˜", "ë¹ŒíŠ¸ì¸", "ìƒˆê²ƒ", "ê¹¨ë—",
            "ì‹ ì¶•", "ì¤€ì‹ ì¶•", "ìˆ˜ë¦¬ì™„ë£Œ", "ë„ë°°ì™„ë£Œ", "ì¥íŒêµì²´", "ì‹±í¬ëŒ€êµì²´",
            "ì¦‰ì‹œì…ì£¼", "ì…ì£¼ê°€ëŠ¥", "ê³µì‹¤", "ì‹¤ì…ì£¼", "ë°”ë¡œì…ì£¼", "í˜‘ì˜ì…ì£¼",
            "ì—­ì„¸ê¶Œ", "ì´ˆì—­ì„¸ê¶Œ", "ë”ë¸”ì—­ì„¸ê¶Œ", "í•™êµ°", "í•™êµì•", "ê³µì›ì•", "ê³µì›ë·°",
            "í•œê°•ë·°", "ì‚°ë·°", "ì˜¤ì…˜ë·°", "ì‹œí‹°ë·°", "ì¡°ë§ì¢‹ìŒ", "ì¡°ë§ê¶Œ", "ë‚¨í–¥",
            "ë² ë€ë‹¤í™•ì¥", "í™•ì¥í˜•", "ë³µì¸µ", "í…Œë¼ìŠ¤", "ì •ì›", "ë§ˆë‹¹", "ì˜¥ìƒ",
            "ì£¼ì°¨ê°€ëŠ¥", "ì£¼ì°¨2ëŒ€", "ë¶„ë¦¬í˜•", "íˆ¬ë£¸", "ì“°ë¦¬ë£¸", "ë°©3ê°œ", "ë°©2ê°œ",
            "í™”ì¥ì‹¤2", "ìš•ì‹¤2ê°œ", "ë“œë ˆìŠ¤ë£¸", "íŒ¬íŠ¸ë¦¬", "ë‹¤ìš©ë„ì‹¤",
            "íƒ‘ì¸µ", "ë¡œì–„ì¸µ", "ê³ ì¸µ", "ì¤‘ì¸µ", "ì €ì¸µ", "1ì¸µ", "ê¼­ëŒ€ê¸°",
            "ì „ì„¸ì•ˆê³ ", "ì „ì„¸ë¼ê³ ", "ì£¼ì¸ì§ê±°ë˜", "ì„¸ì…ììˆìŒ", "ì„¸ë†“ì€",
            "íœíŠ¸í•˜ìš°ìŠ¤", "ë³µë„ì‹", "ê³„ë‹¨ì‹", "ì—˜ë¦¬ë² ì´í„°", "ê²½ë¹„ì‹¤", "ê´€ë¦¬ë¹„ì €ë ´"
        ]
        feature_selectors = [
            ".item_desc", ".feature", ".info_sub", "[class*='desc']",
            ".article_desc", ".item_feature", ".description",
            ".info_article_feature", ".cell_feature", ".data_feature",
            ".item_info_desc", ".tag_list", ".item_tag", "[class*='tag']",
            ".item_detail", ".detail_info", ".sub_info"
        ]
        
        for sel in feature_selectors:
            elem = item.select_one(sel)
            if elem:
                text = elem.get_text(separator=" ", strip=True)
                if text and len(text) > 2:
                    is_ad_only = any(ad in text for ad in ad_keywords) and \
                                 not any(kw in text for kw in meaningful_keywords)
                    if not is_ad_only:
                        cleaned = text
                        for ad in ad_keywords:
                            cleaned = cleaned.replace(ad, "").strip()
                        if cleaned and len(cleaned) > 2:
                            feature_text = cleaned[:100]
                            break
        
        if not feature_text or len(feature_text) < 3:
            found_features = []
            for kw in meaningful_keywords:
                if kw in full_text:
                    found_features.append(kw)
                    if len(found_features) >= 6:
                        break
            if found_features:
                feature_text = ", ".join(found_features)
        
        if not feature_text:
            room_info = []
            room_match = re.search(r'(\d)\s*ë£¸|ë°©\s*(\d)|(\d)\s*ë² ë“œ', full_text)
            bath_match = re.search(r'(\d)\s*ìš•|í™”ì¥ì‹¤\s*(\d)|(\d)\s*ë°°ìŠ¤', full_text)
            if room_match:
                num = room_match.group(1) or room_match.group(2) or room_match.group(3)
                room_info.append(f"ë°©{num}ê°œ")
            if bath_match:
                num = bath_match.group(1) or bath_match.group(2) or bath_match.group(3)
                room_info.append(f"í™”ì¥ì‹¤{num}ê°œ")
            if room_info:
                feature_text = ", ".join(room_info)
        
        article_id = ""
        link = item.select_one("a[href*='articleId']")
        if link:
            href = link.get('href', '')
            id_match = re.search(r'articleId=(\d+)', href)
            if id_match: article_id = id_match.group(1)
        else:
            article_id = item.get('data-article-id', '') or item.get('data-id', '')
        
        ë§¤ë§¤ê°€, ë³´ì¦ê¸ˆ, ì›”ì„¸ = "", "", ""
        if detected_type == "ë§¤ë§¤":
            ë§¤ë§¤ê°€ = price_text.replace("ë§¤ë§¤", "").strip()
        elif detected_type == "ì „ì„¸":
            ë³´ì¦ê¸ˆ = price_text.replace("ì „ì„¸", "").strip()
        else:
            price_clean = price_text.replace("ì›”ì„¸", "").strip()
            if "/" in price_clean:
                parts = price_clean.split("/")
                ë³´ì¦ê¸ˆ = parts[0].strip()
                ì›”ì„¸ = parts[1].strip() if len(parts) > 1 else ""
            else:
                ë³´ì¦ê¸ˆ = price_clean
        
        main_price = PriceConverter.to_int(ë§¤ë§¤ê°€) if detected_type == "ë§¤ë§¤" else PriceConverter.to_int(ë³´ì¦ê¸ˆ)
        price_per_pyeong = PricePerPyeongCalculator.calculate(main_price, pyeong) if pyeong > 0 else 0
        
        return {
            "ë‹¨ì§€ëª…": name, "ë‹¨ì§€ID": cid, "ê±°ë˜ìœ í˜•": detected_type,
            "ë§¤ë§¤ê°€": ë§¤ë§¤ê°€, "ë³´ì¦ê¸ˆ": ë³´ì¦ê¸ˆ, "ì›”ì„¸": ì›”ì„¸,
            "ë©´ì (ã¡)": sqm, "ë©´ì (í‰)": pyeong, 
            "í‰ë‹¹ê°€": price_per_pyeong,
            "í‰ë‹¹ê°€_í‘œì‹œ": PricePerPyeongCalculator.format(price_per_pyeong),
            "ì¸µ/ë°©í–¥": floor_text,
            "íƒ€ì…/íŠ¹ì§•": feature_text, "ë§¤ë¬¼ID": article_id,
            "ìˆ˜ì§‘ì‹œê°": DateTimeHelper.now_string()
        }
>>>>>>> 39500298f217e86700ed82ba5199a76ef9100859
        
    def _check_filters(self, data, ttype):
        if self.area_filter.get("enabled"):
            sqm = data.get("ë©´ì (ã¡)", 0)
            if sqm < self.area_filter.get("min", 0) or sqm > self.area_filter.get("max", 999):
                return False
        if self.price_filter.get("enabled"):
            price_range = self.price_filter.get(ttype, {})
            min_p, max_p = price_range.get("min", 0), price_range.get("max", 999999)
            if ttype == "ë§¤ë§¤": price = PriceConverter.to_int(data.get("ë§¤ë§¤ê°€", "0"))
            else: price = PriceConverter.to_int(data.get("ë³´ì¦ê¸ˆ", "0"))
            if price < min_p or price > max_p: return False
        return True
