import time
import random
import gc
import traceback
from PyQt6.QtCore import QThread, pyqtSignal

try:
    import undetected_chromedriver as uc
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, NoSuchElementException
    UC_AVAILABLE = True
except ImportError:
    UC_AVAILABLE = False

try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
except ImportError:
    BS4_AVAILABLE = False

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

from src.utils.constants import CRAWL_SPEED_PRESETS
from src.utils.helpers import PriceConverter, ChromeParamHelper
from src.utils.retry_handler import RetryHandler
from src.core.item_parser import ItemParser

# Î©îÎ™®Î¶¨ ÏûÑÍ≥ÑÏπò (MB) - Ï¥àÍ≥º Ïãú ÎìúÎùºÏù¥Î≤Ñ Ïû¨ÏãúÏûë
MEMORY_THRESHOLD_MB = 500

class CrawlerThread(QThread):
    log_signal = pyqtSignal(str, int)
    progress_signal = pyqtSignal(int, str, int)  # percent, current_name, remaining_seconds
    item_signal = pyqtSignal(dict)  # deprecated: items_signal(list[dict]) ÏÇ¨Ïö© Í∂åÏû•
    items_signal = pyqtSignal(list)
    stats_signal = pyqtSignal(dict)
    complex_finished_signal = pyqtSignal(str, str, str, int)
    finished_signal = pyqtSignal(list)
    error_signal = pyqtSignal(str)
    alert_triggered_signal = pyqtSignal(str, str, str, float, int)
    BLOCKED_PAGE_PATTERNS = (
        "captcha",
        "Ï∫°Ï∞®",
        "ÏûêÎèôÏûÖÎ†• Î∞©ÏßÄ",
        "ÏûêÎèô ÏûÖÎ†• Î∞©ÏßÄ",
        "Ï†ëÍ∑ºÏù¥ Ï†úÌïú",
        "Ï†ëÏÜçÏù¥ Ï†úÌïú",
        "ÎπÑÏ†ïÏÉÅÏ†ÅÏù∏ Ï†ëÍ∑º",
        "ÏÑúÎπÑÏä§ Ïù¥Ïö©Ïù¥ Ï†úÌïú",
        "verify you are human",
        "robot check",
        "access denied",
        "security check",
        "cloudflare",
        "bot detection",
    )
    
    def __init__(
        self,
        targets,
        trade_types,
        area_filter,
        price_filter,
        db,
        speed="Î≥¥ÌÜµ",
        cache=None,
        ui_batch_interval_ms=120,
        ui_batch_size=30,
        emit_legacy_item_signal=False,
        max_retry_count=3,
        show_new_badge=True,
        show_price_change=True,
        price_change_threshold=0,
        track_disappeared=True,
        history_batch_size=200,
    ):
        super().__init__()
        self.targets = targets
        self.trade_types = trade_types
        self.area_filter = area_filter
        self.price_filter = price_filter
        self.db = db
        self.speed = speed
        self.cache = cache  # v12.0: CrawlCache Ïù∏Ïä§ÌÑ¥Ïä§
        self._running = True
        self.collected_data = []
        self.pending_items = []
        self.stats = {
            "total_found": 0,
            "filtered_out": 0,
            "cache_hits": 0,
            "new_count": 0,
            "price_up": 0,
            "price_down": 0,
            "by_trade_type": {"Îß§Îß§": 0, "Ï†ÑÏÑ∏": 0, "ÏõîÏÑ∏": 0},
        }
        self.start_time = None
        self.items_per_second = 0
        try:
            retries = max(0, int(max_retry_count))
        except (TypeError, ValueError):
            retries = 3
        self.retry_handler = RetryHandler(max_retries=retries)
        self.ui_batch_interval_ms = max(20, int(ui_batch_interval_ms))
        self.ui_batch_size = max(1, int(ui_batch_size))
        self.emit_legacy_item_signal = bool(emit_legacy_item_signal)
        self.show_new_badge = bool(show_new_badge)
        self.show_price_change = bool(show_price_change)
        try:
            self.price_change_threshold = max(0, int(price_change_threshold))
        except (TypeError, ValueError):
            self.price_change_threshold = 0
        self.track_disappeared = bool(track_disappeared)
        try:
            self.history_batch_size = max(20, int(history_batch_size))
        except (TypeError, ValueError):
            self.history_batch_size = 200
        self._last_batch_flush_at = time.monotonic()
        self._history_state_cache = {}
        self._alert_rules_cache = {}
        self._pending_history_rows = []
    
    def stop(self): self._running = False
    def log(self, msg, level=20): self.log_signal.emit(msg, level)

    def _push_item(self, item):
        self.collected_data.append(item)
        self.pending_items.append(item)
        self.stats["total_found"] += 1
        if self.emit_legacy_item_signal:
            self.item_signal.emit(item)
        self._flush_pending_items_if_needed()

    def _flush_pending_items_if_needed(self, force=False):
        if not self.pending_items:
            return
        elapsed_ms = (time.monotonic() - self._last_batch_flush_at) * 1000
        if force or len(self.pending_items) >= self.ui_batch_size or elapsed_ms >= self.ui_batch_interval_ms:
            batch = list(self.pending_items)
            self.pending_items.clear()
            self.items_signal.emit(batch)
            self.stats_signal.emit({
                "total_found": self.stats.get("total_found", 0),
                "filtered_out": self.stats.get("filtered_out", 0),
                "cache_hits": self.stats.get("cache_hits", 0),
                "new_count": self.stats.get("new_count", 0),
                "price_up": self.stats.get("price_up", 0),
                "price_down": self.stats.get("price_down", 0),
                "by_trade_type": dict(self.stats.get("by_trade_type", {})),
            })
            self._last_batch_flush_at = time.monotonic()

    @staticmethod
    def _row_get(row, key, default=None):
        if row is None:
            return default
        try:
            if isinstance(row, dict):
                return row.get(key, default)
            return row[key]
        except Exception:
            return default

    def _cache_key(self, complex_id, trade_type):
        return (str(complex_id or ""), str(trade_type or ""))

    def _get_history_state_map(self, complex_id, trade_type):
        key = (str(complex_id or ""), "*")
        if key in self._history_state_cache:
            return self._history_state_cache[key]
        history_map = {}
        if self.db and complex_id:
            try:
                history_map = self.db.get_article_history_state_bulk(complex_id)
            except Exception as e:
                self.log(f"   ‚ö†Ô∏è Ïù¥Î†• ÏÉÅÌÉú Î°úÎìú Ïã§Ìå®: {e}", 30)
        self._history_state_cache[key] = history_map or {}
        return self._history_state_cache[key]

    def _get_alert_rules(self, complex_id, trade_type):
        key = self._cache_key(complex_id, trade_type)
        if key in self._alert_rules_cache:
            return self._alert_rules_cache[key]
        rules = []
        if self.db and complex_id and trade_type:
            try:
                rules = self.db.get_enabled_alert_rules(complex_id, trade_type)
            except Exception as e:
                self.log(f"   ‚ö†Ô∏è ÏïåÎ¶º Î£∞ Î°úÎìú Ïã§Ìå®: {e}", 30)
        self._alert_rules_cache[key] = rules or []
        return self._alert_rules_cache[key]

    def _flush_history_updates_fallback(self, rows):
        if not self.db:
            return 0
        saved = 0
        for row in rows:
            try:
                ok = self.db.update_article_history(
                    article_id=row.get("article_id", ""),
                    complex_id=row.get("complex_id", ""),
                    complex_name=row.get("complex_name", ""),
                    trade_type=row.get("trade_type", ""),
                    price=int(row.get("price", 0) or 0),
                    price_text=row.get("price_text", ""),
                    area=float(row.get("area", 0) or 0),
                    floor=row.get("floor", ""),
                    feature=row.get("feature", ""),
                )
                if ok:
                    saved += 1
            except Exception:
                continue
        return saved

    def _flush_history_updates(self, force=False):
        if not self._pending_history_rows:
            return 0
        if not force and len(self._pending_history_rows) < self.history_batch_size:
            return 0
        rows = list(self._pending_history_rows)
        self._pending_history_rows.clear()
        if not self.db:
            return 0

        try:
            saved = int(self.db.upsert_article_history_bulk(rows) or 0)
            if saved == len(rows):
                return saved
            self.log(
                f"   ‚ö†Ô∏è Ïù¥Î†• ÏùºÍ¥Ñ Ï†ÄÏû• ÏùºÎ∂Ä Ïã§Ìå® ({saved}/{len(rows)}), Í∞úÎ≥Ñ Ïû¨ÏãúÎèÑ...",
                30,
            )
        except Exception as e:
            self.log(f"   ‚ö†Ô∏è Ïù¥Î†• ÏùºÍ¥Ñ Ï†ÄÏû• Ïã§Ìå®: {e} (Í∞úÎ≥Ñ Ïû¨ÏãúÎèÑ)", 30)
        return self._flush_history_updates_fallback(rows)

    def _enrich_item_with_history_and_alerts(self, data):
        if not isinstance(data, dict):
            return data

        trade_type = str(data.get("Í±∞ÎûòÏú†Ìòï", "") or "")
        complex_id = str(data.get("Îã®ÏßÄID", "") or "")
        article_id = str(data.get("Îß§Î¨ºID", "") or "")
        complex_name = str(data.get("Îã®ÏßÄÎ™Ö", "") or "")

        if trade_type == "Îß§Îß§":
            price_text = str(data.get("Îß§Îß§Í∞Ä", "") or "")
        else:
            deposit = str(data.get("Î≥¥Ï¶ùÍ∏à", "") or "")
            monthly = str(data.get("ÏõîÏÑ∏", "") or "")
            price_text = f"{deposit}/{monthly}" if monthly else deposit
        price_int = PriceConverter.to_int(price_text.split("/")[0] if "/" in price_text else price_text)

        area_pyeong = 0.0
        try:
            area_pyeong = float(data.get("Î©¥Ï†Å(Ìèâ)", 0) or 0)
        except (TypeError, ValueError):
            area_pyeong = 0.0

        is_new = False
        raw_price_change = 0
        if article_id and complex_id and price_int > 0:
            history_map = self._get_history_state_map(complex_id, trade_type)
            prev = history_map.get(article_id)
            prev_price = int(self._row_get(prev, "price", 0) or 0)
            is_new = prev is None
            raw_price_change = 0 if is_new else price_int - prev_price

            history_map[article_id] = {
                "price": price_int,
                "status": "active",
                "last_price": prev_price if prev_price > 0 else price_int,
                "price_change": raw_price_change,
            }

            self._pending_history_rows.append(
                {
                    "article_id": article_id,
                    "complex_id": complex_id,
                    "complex_name": complex_name,
                    "trade_type": trade_type,
                    "price": price_int,
                    "price_text": price_text,
                    "area": area_pyeong,
                    "floor": str(data.get("Ï∏µ/Î∞©Ìñ•", "") or ""),
                    "feature": str(data.get("ÌÉÄÏûÖ/ÌäπÏßï", "") or ""),
                    "last_price": prev_price if prev_price > 0 else price_int,
                }
            )
            self._flush_history_updates(force=False)

        price_change = int(raw_price_change)
        if self.price_change_threshold > 0 and abs(price_change) < self.price_change_threshold:
            price_change = 0
        if is_new:
            self.stats["new_count"] = int(self.stats.get("new_count", 0)) + 1
        if price_change > 0:
            self.stats["price_up"] = int(self.stats.get("price_up", 0)) + 1
        elif price_change < 0:
            self.stats["price_down"] = int(self.stats.get("price_down", 0)) + 1

        visible_is_new = bool(is_new) if self.show_new_badge else False
        visible_price_change = int(price_change) if self.show_price_change else 0

        data["is_new"] = visible_is_new
        data["Ïã†Í∑úÏó¨Î∂Ä"] = visible_is_new
        data["price_change"] = visible_price_change
        data["Í∞ÄÍ≤©Î≥ÄÎèô"] = visible_price_change

        if complex_id and trade_type and area_pyeong > 0 and price_int > 0:
            rules = self._get_alert_rules(complex_id, trade_type)
            for rule in rules:
                area_min = float(self._row_get(rule, "area_min", 0) or 0)
                area_max = float(self._row_get(rule, "area_max", 999999) or 999999)
                price_min = int(self._row_get(rule, "price_min", 0) or 0)
                price_max = int(self._row_get(rule, "price_max", 999999999) or 999999999)
                if not (area_min <= area_pyeong <= area_max):
                    continue
                if not (price_min <= price_int <= price_max):
                    continue
                alert_id = int(self._row_get(rule, "id", 0) or 0)
                alert_name = str(self._row_get(rule, "complex_name", complex_name) or complex_name)
                should_emit = True
                if alert_id > 0 and article_id:
                    try:
                        should_emit = bool(
                            self.db.record_alert_notification(
                                alert_id=alert_id,
                                article_id=article_id,
                                complex_id=complex_id,
                            )
                        )
                    except Exception as e:
                        should_emit = True
                        self.log(f"   ‚ö†Ô∏è ÏïåÎ¶º dedup Í∏∞Î°ù Ïã§Ìå® (emit Ïú†ÏßÄ): {e}", 30)
                elif alert_id > 0 and not article_id:
                    self.log("   ‚ÑπÔ∏è Îß§Î¨ºID ÏóÜÏùå: ÏïåÎ¶º dedup ÏÉùÎûµ", 10)

                if not should_emit:
                    continue
                self.alert_triggered_signal.emit(
                    alert_name,
                    trade_type,
                    price_text,
                    float(area_pyeong),
                    alert_id,
                )

        return data
    
    def _init_driver(self):
        """Chrome ÎìúÎùºÏù¥Î≤Ñ Ï¥àÍ∏∞Ìôî Î∞è ÏÑ§Ï†ï"""
        
        # Chrome Î≤ÑÏ†Ñ ÏûêÎèô Í∞êÏßÄ
        detected_version = ChromeParamHelper.get_chrome_major_version()
        version_msg = f" (Í∞êÏßÄÎêú Î≤ÑÏ†Ñ: {detected_version})" if detected_version else " (Î≤ÑÏ†Ñ ÏûêÎèô Í∞êÏßÄ)"
        self.log(f"üîß Chrome ÎìúÎùºÏù¥Î≤Ñ Ï¥àÍ∏∞Ìôî Ï§ë...{version_msg}")
        
        options = uc.ChromeOptions()
        options.add_argument("--headless=new")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        options.add_argument("--disable-software-rasterizer")
        options.add_argument("--window-size=1920,1080")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
        options.add_argument("--log-level=3")
        
        driver = None
        try:
            # Í∞êÏßÄÎêú Î≤ÑÏ†ÑÏù¥ ÏûàÏúºÎ©¥ Ìï¥Îãπ Î≤ÑÏ†Ñ ÏÇ¨Ïö©, ÏóÜÏúºÎ©¥ None (ÏµúÏã†/ÏûêÎèô)
            driver = uc.Chrome(options=options, version_main=detected_version)
            self.log("‚úÖ Chrome ÎìúÎùºÏù¥Î≤Ñ Ï¥àÍ∏∞Ìôî ÏÑ±Í≥µ")
        except Exception as e:
            self.log(f"‚ö†Ô∏è Headless Ïã§Ìå®, ÏùºÎ∞ò Î™®Îìú ÏãúÎèÑ... ({e})", 30)
            options2 = uc.ChromeOptions()
            options2.add_argument("--no-sandbox")
            options2.add_argument("--disable-dev-shm-usage")
            options2.add_argument("--disable-gpu")
            options2.add_argument("--window-size=1920,1080")
            options2.add_argument("--start-minimized")
            driver = uc.Chrome(options=options2, version_main=detected_version)
            self.log("‚úÖ Chrome ÎìúÎùºÏù¥Î≤Ñ Ï¥àÍ∏∞Ìôî ÏÑ±Í≥µ (ÏùºÎ∞ò Î™®Îìú)")
        
        if driver:
            driver.set_page_load_timeout(30)
            driver.implicitly_wait(5)
            
        return driver

    def run(self):
        if not UC_AVAILABLE or not BS4_AVAILABLE:
            self.error_signal.emit("ÌïÑÏàò ÎùºÏù¥Î∏åÎü¨Î¶¨ ÎØ∏ÏÑ§Ïπò\npip install undetected-chromedriver beautifulsoup4")
            return
            
        driver = None
        self.start_time = time.time()
        
        try:
            self.log("üöÄ ÌÅ¨Î°§ÎßÅ ÏãúÏûë...")
            driver = self._init_driver()
            if not driver:
                raise Exception("ÎìúÎùºÏù¥Î≤Ñ Ï¥àÍ∏∞Ìôî Ïã§Ìå®")
            
            total = len(self.targets) * len(self.trade_types)
            current = 0
            processed_complexes = 0  # Ï≤òÎ¶¨Ìïú Îã®ÏßÄ Ïàò
            processed_target_pairs = set()
            
            for name, cid in self.targets:
                if not self._running: break
                
                # v14.0: Î©îÎ™®Î¶¨ Í∏∞Î∞ò ÎìúÎùºÏù¥Î≤Ñ Ïû¨ÏãúÏûë (500MB ÏûÑÍ≥ÑÏπò)
                should_restart = False
                if PSUTIL_AVAILABLE:
                    memory_mb = psutil.Process().memory_info().rss / (1024 * 1024)
                    if memory_mb > MEMORY_THRESHOLD_MB:
                        should_restart = True
                        self.log(f"üîÑ Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ {memory_mb:.0f}MB Ï¥àÍ≥º, ÎìúÎùºÏù¥Î≤Ñ Ïû¨ÏãúÏûë...")
                else:
                    # psutil ÎØ∏ÏÑ§Ïπò Ïãú Í∏∞Ï°¥ Î∞©Ïãù (3Îã®ÏßÄÎßàÎã§)
                    if processed_complexes > 0 and processed_complexes % 3 == 0:
                        should_restart = True
                        self.log("üîÑ Chrome ÎìúÎùºÏù¥Î≤Ñ Ïû¨ÏãúÏûë (Î©îÎ™®Î¶¨ Ï†ïÎ¶¨)...")
                
                if should_restart:
                    try:
                        driver.quit()
                    except Exception as e:
                        self.log(f"‚ö†Ô∏è ÎìúÎùºÏù¥Î≤Ñ Ï¢ÖÎ£å Ïã§Ìå® (Î¨¥Ïãú): {e}", 30)
                    driver = None
                    gc.collect()
                    time.sleep(1)
                    
                    driver = self._init_driver()
                    if not driver:
                        raise Exception("ÎìúÎùºÏù¥Î≤Ñ Ïû¨ÏãúÏûë Ïã§Ìå®")
                
                complex_count = 0
                for ttype in self.trade_types:
                    if not self._running: break
                    if cid and ttype:
                        processed_target_pairs.add((str(cid), str(ttype)))
                    current += 1
                    
                    # ÏòàÏÉÅ ÎÇ®ÏùÄ ÏãúÍ∞Ñ Í≥ÑÏÇ∞
                    elapsed = time.time() - self.start_time
                    avg_time = elapsed / current if current > 0 else 5
                    remaining = int(avg_time * (total - current))
                    
                    self.progress_signal.emit(int(current / total * 100), f"{name} ({ttype})", remaining)
                    self.log(f"\\nüìç [{current}/{total}] {name} - {ttype}")
                    
                    try:
                        batch_result = self._crawl(driver, name, cid, ttype)
                        count = int(batch_result.get("count", 0))
                        complex_count += count
                        self.stats["by_trade_type"][ttype] = self.stats["by_trade_type"].get(ttype, 0) + count
                        self.log(f"   ‚úÖ {count}Í±¥ ÏàòÏßë")
                    except Exception as e:
                        self.log(f"   ‚ùå Ïò§Î•ò: {e}", 40)
                        self.log(f"   ÏÉÅÏÑ∏: {traceback.format_exc()}", 40)
                        
                        # ÏπòÎ™ÖÏ†Å Ïò§Î•ò(ÏÑ∏ÏÖò Ï¢ÖÎ£å Îì±) Î∞úÏÉù Ïãú ÎìúÎùºÏù¥Î≤Ñ Ïû¨ÏãúÏûë ÏãúÎèÑ
                        if "SessionNotCreatedException" in str(e) or "NoSuchWindowException" in str(e) or "WebDriverException" in str(e):
                             self.log("‚ö†Ô∏è ÎìúÎùºÏù¥Î≤Ñ ÏÑ∏ÏÖò Ïò§Î•ò Í∞êÏßÄ, Ïû¨ÏãúÏûë ÏãúÎèÑ...", 30)
                             try:
                                 driver.quit()
                             except Exception as quit_err:
                                 self.log(f"‚ö†Ô∏è ÎìúÎùºÏù¥Î≤Ñ Ï¢ÖÎ£å Ïã§Ìå® (Î¨¥Ïãú): {quit_err}", 30)
                             driver = self._init_driver()
                    
                    speed_cfg = CRAWL_SPEED_PRESETS.get(self.speed, CRAWL_SPEED_PRESETS["Î≥¥ÌÜµ"])
                    time.sleep(random.uniform(speed_cfg["min"], speed_cfg["max"]))

                self._flush_history_updates(force=True)
                
                self.complex_finished_signal.emit(name, cid, ",".join(self.trade_types), complex_count)
                processed_complexes += 1

            # Ï†ÑÏ≤¥ ÏàòÏßëÏùÑ Ï†ïÏÉÅ Ï¢ÖÎ£åÌïú Í≤ΩÏö∞ÏóêÎßå ÏÜåÎ©∏ Îß§Î¨º Ï≤òÎ¶¨
            if self.track_disappeared and self._running and self.db:
                try:
                    if processed_target_pairs and hasattr(self.db, "mark_disappeared_articles_for_targets"):
                        disappeared = int(
                            self.db.mark_disappeared_articles_for_targets(
                                list(sorted(processed_target_pairs))
                            )
                            or 0
                        )
                    else:
                        disappeared = int(self.db.mark_disappeared_articles() or 0)
                    if disappeared > 0:
                        self.log(f"üóëÔ∏è ÏÜåÎ©∏ Îß§Î¨º {disappeared}Í±¥ Ï≤òÎ¶¨")
                except Exception as e:
                    self.log(f"‚ö†Ô∏è ÏÜåÎ©∏ Îß§Î¨º Ï≤òÎ¶¨ Ïã§Ìå®: {e}", 30)
            
            self._flush_pending_items_if_needed(force=True)
            self._flush_history_updates(force=True)
            self.log(f"\\n{'='*50}\\n‚úÖ ÏôÑÎ£å! Ï¥ù {len(self.collected_data)}Í±¥")
        except Exception as e:
            self.log(f"‚ùå ÏπòÎ™ÖÏ†Å Ïò§Î•ò: {e}", 40)
            self.log(f"ÏÉÅÏÑ∏:\\n{traceback.format_exc()}", 40)
            self.error_signal.emit(str(e))
        finally:
            self._flush_pending_items_if_needed(force=True)
            self._flush_history_updates(force=True)
            if driver:
                try:
                    driver.quit()
                    self.log("‚úÖ Chrome ÎìúÎùºÏù¥Î≤Ñ Ï¢ÖÎ£å ÏôÑÎ£å")
                except Exception as e:
                    self.log(f"‚ö†Ô∏è Chrome ÎìúÎùºÏù¥Î≤Ñ Ï¢ÖÎ£å Ï§ë Ïò§Î•ò: {e}", 30)
            self.finished_signal.emit(self.collected_data)
    
    def _crawl(self, driver, name, cid, ttype):
        # v12.0: Ï∫êÏãú ÌôïÏù∏
        if self.cache:
            cached_items = self.cache.get(cid, ttype)
            if cached_items:
                self.log(f"   üíæ Ï∫êÏãú ÌûàÌä∏! {len(cached_items)}Í±¥ Î°úÎìú")
                self.stats["cache_hits"] = self.stats.get("cache_hits", 0) + 1
                matched_count = 0
                for raw_item in cached_items:
                    if not isinstance(raw_item, dict):
                        continue
                    processed_item = self._enrich_item_with_history_and_alerts(dict(raw_item))
                    if self._check_filters(processed_item, ttype):
                        self._push_item(processed_item)
                        matched_count += 1
                    else:
                        self.stats["filtered_out"] += 1
                self._flush_history_updates(force=True)
                self._flush_pending_items_if_needed(force=True)
                return {"count": matched_count, "cache_hit": True, "raw_count": len(cached_items)}
        
        trade_param = {"Îß§Îß§": "A1", "Ï†ÑÏÑ∏": "B1", "ÏõîÏÑ∏": "B2"}.get(ttype, "A1")
        url = f"https://new.land.naver.com/complexes/{cid}?ms=37.5,127,16&a=APT&e=RETAIL&tradeTypes={trade_param}"

        try:
            parse_result = self.retry_handler.execute_with_retry(
                self._crawl_once,
                driver,
                name,
                cid,
                ttype,
                url,
            )
        except Exception as e:
            self.log(f"   ‚ùå {name}({ttype}) ÌÅ¨Î°§ÎßÅ Ïã§Ìå®: {e}", 40)
            raise
        count = int(parse_result.get("count", 0))
        
        # v14.2: ÌïÑÌÑ∞ ÌÜµÍ≥º Ïó¨Î∂ÄÏôÄ Î¨¥Í¥ÄÌïòÍ≤å raw_items Ï∫êÏãú Ï†ÄÏû•
        if self.cache:
            raw_items = parse_result.get("raw_items", [])
            if raw_items:
                self.cache.set(cid, ttype, raw_items)
        
        self._flush_history_updates(force=True)
        self._flush_pending_items_if_needed(force=True)
        return {
            "count": count,
            "cache_hit": False,
            "raw_count": int(parse_result.get("raw_count", 0)),
        }

    def _crawl_once(self, driver, name, cid, ttype, url):
        self.log("   üîó URL Ï†ëÏÜç Ï§ë...")
        driver.get(url)
        self._assert_not_blocked_page(driver, context="Ï¥àÍ∏∞ ÌéòÏù¥ÏßÄ")

        # v14.0: ÎèôÏ†Å ÎåÄÍ∏∞ - ÌéòÏù¥ÏßÄ Î°úÎìú ÏôÑÎ£åÍπåÏßÄ ÎåÄÍ∏∞
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located(("css selector", ".article_list, .item_list, .complex_list, [class*='article']"))
            )
        except TimeoutException:
            self.log("   ‚ö†Ô∏è Îß§Î¨º Î¶¨Ïä§Ìä∏ Î°úÎìú ÎåÄÍ∏∞ ÏãúÍ∞Ñ Ï¥àÍ≥º, Í≥ÑÏÜç ÏßÑÌñâ...", 30)
        self._assert_not_blocked_page(driver, context="Î™©Î°ù ÎåÄÍ∏∞")

        try:
            article_tab = driver.find_element("css selector", "a[href*='articleList'], .tab_item[data-tab='article']")
            article_tab.click()
            # v14.0: ÌÉ≠ ÌÅ¥Î¶≠ ÌõÑ ÎèôÏ†Å ÎåÄÍ∏∞
            try:
                WebDriverWait(driver, 5).until(
                    EC.presence_of_element_located(("css selector", ".item_article, .item_inner"))
                )
            except TimeoutException:
                self.log("   ‚ÑπÔ∏è Îß§Î¨º ÌÉ≠ Î°úÎìú ÎåÄÍ∏∞ ÏãúÍ∞Ñ Ï¥àÍ≥º (Î¨¥Ïãú)", 10)
        except (NoSuchElementException, Exception) as e:
            # ÌÉ≠ ÌÅ¥Î¶≠ Ïã§Ìå®Îäî Ï†ïÏÉÅÏ†ÅÏù∏ ÏÉÅÌô©Ïùº Ïàò ÏûàÏùå (ÌÉ≠Ïù¥ ÏóÜÎäî Í≤ΩÏö∞)
            self.log(f"   ‚ÑπÔ∏è Îß§Î¨º ÌÉ≠ Ï∞æÍ∏∞ Ïã§Ìå® (Ï†ïÏÉÅ): {type(e).__name__}", 10)

        self._assert_not_blocked_page(driver, context="ÌÉ≠ ÏßÑÏûÖ")
        self._scroll(driver)
        self._assert_not_blocked_page(driver, context="Ïä§ÌÅ¨Î°§ ÏôÑÎ£å")

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        return self._parse(soup, name, cid, ttype)

    def _detect_block_signal(self, title, page_source):
        title_lower = str(title or "").lower()
        source_lower = str(page_source or "").lower()
        source_head = source_lower[:20000]
        haystack = f"{title_lower}\n{source_head}"
        for pattern in self.BLOCKED_PAGE_PATTERNS:
            if pattern in haystack:
                return pattern
        return None

    def _assert_not_blocked_page(self, driver, context=""):
        try:
            title = driver.title
        except Exception:
            title = ""
        try:
            page_source = driver.page_source
        except Exception:
            page_source = ""

        signal = self._detect_block_signal(title, page_source)
        if signal:
            ctx = f" ({context})" if context else ""
            self.log(f"   ‚ö†Ô∏è Ï∞®Îã®/Î∞©Ïñ¥ ÌéòÏù¥ÏßÄ Í∞êÏßÄ{ctx}: {signal}", 30)
            raise RuntimeError(f"temporary blocked page detected{ctx}: {signal}")

    def _get_item_state(self, driver, selectors):
        script = """
            const selector = arguments[0];
            const nodes = Array.from(document.querySelectorAll(selector));
            const ids = [];
            for (const node of nodes) {
                let id =
                    node.getAttribute('data-article-id') ||
                    node.getAttribute('data-id') ||
                    node.getAttribute('id') ||
                    '';
                if (!id) {
                    const anchor = node.querySelector("a[href*='articleId=']");
                    if (anchor) {
                        const href = anchor.getAttribute('href') || '';
                        const m = href.match(/articleId=(\\d+)/);
                        if (m) {
                            id = m[1];
                        }
                    }
                }
                if (id) {
                    ids.push(String(id));
                }
            }
            return {count: nodes.length, ids: ids};
        """
        try:
            state = driver.execute_script(script, selectors) or {}
        except Exception:
            return 0, set()
        count = int(state.get("count", 0) or 0)
        raw_ids = state.get("ids", [])
        if not isinstance(raw_ids, list):
            raw_ids = []
        return count, {str(x) for x in raw_ids if x is not None}

    def _detect_scroll_container(self, driver):
        script = """
            const candidates = [];
            const seedSelectors = [
                '.article_list',
                '.item_list',
                '.list_contents',
                '[class*="article_list"]',
                '[class*="item_list"]',
                '[class*="ArticleList"]',
                '[class*="List"]'
            ];
            for (const sel of seedSelectors) {
                candidates.push(...Array.from(document.querySelectorAll(sel)));
            }
            if (candidates.length === 0) {
                candidates.push(...Array.from(document.querySelectorAll('div, section, ul')));
            }
            let best = null;
            let bestScroll = 0;
            for (const el of candidates.slice(0, 400)) {
                const style = window.getComputedStyle(el);
                const overflowY = style.overflowY || '';
                if (!(overflowY.includes('auto') || overflowY.includes('scroll'))) {
                    continue;
                }
                const scrollGap = el.scrollHeight - el.clientHeight;
                if (scrollGap > 40 && scrollGap > bestScroll) {
                    best = el;
                    bestScroll = scrollGap;
                }
            }
            window.__naver_scroll_container = best;
            return !!best;
        """
        try:
            return bool(driver.execute_script(script))
        except Exception:
            return False

    def _scroll_once(self, driver, use_container):
        if use_container:
            script = """
                const container = window.__naver_scroll_container;
                if (container) {
                    container.scrollTop = container.scrollHeight;
                    return true;
                }
                return false;
            """
            try:
                if bool(driver.execute_script(script)):
                    return True
            except Exception:
                pass
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight)")
        return False
    
    def _scroll(self, driver):
        """v14.2: ÎÇ¥Î∂Ä Ïª®ÌÖåÏù¥ÎÑà Ïö∞ÏÑ† + window Ìè¥Î∞± Ïä§ÌÅ¨Î°§"""
        try:
            selectors = ".item_article, .item_inner, .article_item, [class*='ArticleItem']"
            seen_ids = set()
            last_count = -1
            stable_count = 0
            max_scroll_attempts = 18
            use_container = self._detect_scroll_container(driver)
            if use_container:
                self.log("   ‚ÑπÔ∏è ÎÇ¥Î∂Ä Ïä§ÌÅ¨Î°§ Ïª®ÌÖåÏù¥ÎÑà Í∞êÏßÄ, Ïª®ÌÖåÏù¥ÎÑà Ïä§ÌÅ¨Î°§ Ïö∞ÏÑ† Ï†ÅÏö©", 10)
            
            for _ in range(max_scroll_attempts):
                if not self._running:
                    break

                current_count, current_ids = self._get_item_state(driver, selectors)
                new_ids = current_ids - seen_ids
                seen_ids.update(current_ids)

                if current_count == last_count and not new_ids:
                    stable_count += 1
                    if stable_count >= 2:
                        break
                else:
                    stable_count = 0
                    last_count = current_count

                used_container = self._scroll_once(driver, use_container=use_container)
                if use_container and not used_container:
                    self.log("   ‚ÑπÔ∏è ÎÇ¥Î∂Ä Ïª®ÌÖåÏù¥ÎÑà Ïä§ÌÅ¨Î°§ Ïã§Ìå®, window Ïä§ÌÅ¨Î°§Î°ú Ìè¥Î∞±", 10)
                    use_container = False

                time.sleep(0.8)
                
        except Exception as e:
            self.log(f"   ‚ö†Ô∏è Ïä§ÌÅ¨Î°§ Ïò§Î•ò: {e}", 30)
    
    def _parse(self, soup, name, cid, ttype):
        raw_items = []
        found_items = ItemParser.find_items(soup)
        
        if found_items:
            # ÏÑ†ÌÉùÏûê Î°úÍπÖ (ItemParser ÎÇ¥Î∂Ä ÎîîÎ≤ÑÍ∑∏ Î°úÍ∑∏ÏôÄ Î≥ÑÍ∞úÎ°ú ÏÇ¨Ïö©ÏûêÏóêÍ≤å ÏßÑÌñâÏÉÅÌô© ÌëúÏãú)
            self.log(f"   üîç ÌååÏã± ÎåÄÏÉÅ: {len(found_items)}Í∞ú")
        else:
            self.log("   ‚ö†Ô∏è ÌååÏã± ÎåÄÏÉÅ Ìï≠Î™©ÏùÑ Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§.", 10)
            return {"count": 0, "raw_items": [], "raw_count": 0}
        
        matched_count, skipped_type = 0, 0
        
        for item in found_items:
            if not self._running: break
            try:
                data = ItemParser.parse_element(item, name, cid, ttype)
                if data and data.get("Î©¥Ï†Å(„é°)", 0) > 0:
                    detected_type = data.get("Í±∞ÎûòÏú†Ìòï", "")
                    if detected_type == ttype:
                        raw_items.append(dict(data))
                        enriched = self._enrich_item_with_history_and_alerts(data)
                        if self._check_filters(enriched, ttype):
                            self._push_item(enriched)
                            matched_count += 1
                        else:
                            self.stats["filtered_out"] += 1
                    else:
                        skipped_type += 1
            except Exception as e:
                self.log(f"   ‚ö†Ô∏è Ìï≠Î™© ÌååÏã± Ï§ë Ïò§Î•ò: {e}", 30)
        
        if skipped_type > 0:
            self.log(f"   ‚ÑπÔ∏è Îã§Î•∏ Í±∞ÎûòÏú†Ìòï {skipped_type}Í±¥ Ï†úÏô∏ (ÏöîÏ≤≠: {ttype})")
        
        return {
            "count": matched_count,
            "raw_items": raw_items,
            "raw_count": len(found_items),
        }

        
    def _check_filters(self, data, ttype):
        if self.area_filter.get("enabled"):
            sqm = data.get("Î©¥Ï†Å(„é°)", 0)
            if sqm < self.area_filter.get("min", 0) or sqm > self.area_filter.get("max", 999):
                return False
        if self.price_filter.get("enabled"):
            price_range = self.price_filter.get(ttype, {}) or {}
            if ttype == "Îß§Îß§":
                min_p = price_range.get("min", 0)
                max_p = price_range.get("max", 999999)
                price = PriceConverter.to_int(data.get("Îß§Îß§Í∞Ä", "0"))
                if price < min_p or price > max_p:
                    return False
            elif ttype == "ÏõîÏÑ∏":
                deposit_min = price_range.get("deposit_min", price_range.get("min", 0))
                deposit_max = price_range.get("deposit_max", price_range.get("max", 999999))
                rent_min = price_range.get("rent_min", price_range.get("min", 0))
                rent_max = price_range.get("rent_max", price_range.get("max", 999999))
                deposit = PriceConverter.to_int(data.get("Î≥¥Ï¶ùÍ∏à", "0"))
                monthly_rent = PriceConverter.to_int(data.get("ÏõîÏÑ∏", "0"))
                if deposit < deposit_min or deposit > deposit_max:
                    return False
                if monthly_rent < rent_min or monthly_rent > rent_max:
                    return False
            else:
                min_p = price_range.get("min", 0)
                max_p = price_range.get("max", 999999)
                price = PriceConverter.to_int(data.get("Î≥¥Ï¶ùÍ∏à", "0"))
                if price < min_p or price > max_p:
                    return False
        return True
