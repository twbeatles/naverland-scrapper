# 🏠 네이버 부동산 매물 크롤러 Pro Plus (v11.0)

네이버 부동산의 아파트 매물 정보를 수집, 분석, 관리할 수 있는 강력한 데스크톱 애플리케이션입니다.  
다중 단지 동시 크롤링, 실시간 가격 변동 추적, 신규 매물 알림, 엑셀 내보내기 등을 제공합니다.

**제작**: Claude Opus 4.5, Gemini 3.0 Pro를 이용하여 지속 개선 중

---

## ✨ 주요 기능

### 🆕 v11.0 신규 기능 (전면 리팩토링)

- **🖥️ HiDPI 디스플레이 지원**: 고해상도 디스플레이에서 선명한 UI 표시
- **🔔 Toast 알림 시스템**: 비침습적이고 직관적인 사용자 피드백 (4가지 타입: success, error, warning, info)
- **🐛 예외 처리 강화**: Bare except 문 제거 및 구체적인 예외 타입 지정으로 디버깅 용이
- **📝 타입 힌트 추가**: 코드 가독성 및 유지보수성 향상
- **⚡ 코드 품질 개선**: 중복 코드 제거 및 최적화로 성능 향상
- **🔒 스레드 안전성 강화**: 안정적인 멀티스레드 크롤링
- **💾 메모리 관리 최적화**: 대량 데이터 수집 시 안정적인 성능 유지

### v10.5 기능

- **🎨 현대적인 UI 테마**: Glassmorphism 효과, 그라데이션 버튼, 개선된 호버 효과
- **🌗 다크/라이트 모드**: 눈의 피로를 줄이는 색상 대비 및 가독성
- **🗑️ 자동 로그 정리**: 30일 이상 지난 로그 파일 자동 삭제
- **⚡ 성능 최적화**: 스레드 안전성 강화 및 리소스 정리 개선

### v10.0 기능

- **📉 가격 변동 그래프**: 이전 수집 기록과 비교하여 가격 상승/하락 추적 및 그래프 표시

### v7.3 기능

- **📉 가격 변동 추적**: 이전 기록과 비교하여 가격 변동 하이라이트
- **🆕 신규 매물 배지**: 새로 등록된 매물에 'NEW' 배지 표시
- **🔍 고급 필터링**: 가격, 면적, 층수, 키워드 등 상세 조건 필터
- **📊 엑셀 템플릿**: 원하는 컬럼만 선택하여 엑셀 저장
- **🔗 URL 일괄 등록**: 여러 네이버 부동산 URL 한 번에 등록
- **📝 특징 파싱 개선**: 광고 멘트 필터링, 핵심 특징만 추출

### 핵심 기능

- ✅ **다중 단지 수집**: 여러 아파트 단지 동시 크롤링
- ✅ **데이터베이스 관리**: sqlite3 기반 로컬 DB에 안전하게 저장
- ✅ **그룹 관리**: 관심 단지를 그룹별로 묶어 관리
- ✅ **시세 히스토리**: 단지별/평형별 시세 변화 그래프 축적
- ✅ **알림 시스템**: 조건에 맞는 매물 발견 시 알림
- ✅ **편의 기능**: 트레이 최소화, 예상 소요 시간, 결과 요약 대시보드

---

## 🛠 설치 및 실행

### 1. 필수 요구 사항

- **Python**: 3.8 이상
- **Chrome 브라우저**: 최신 버전 권장

### 2. 라이브러리 설치

```bash
pip install PyQt6 undetected-chromedriver beautifulsoup4 openpyxl plyer matplotlib
```

### 3. 프로그램 실행

```bash
python "부동산 매물 크롤러 v11.0.py"
```

### 4. 실행 파일 빌드 (선택사항)

PyInstaller로 실행 파일 생성:

```bash
pip install pyinstaller
pyinstaller realestate_crawler.spec
```

빌드 완료 후 `dist/네이버부동산크롤러_v11.0/` 폴더에서 실행 파일 확인

---

## 📖 사용 가이드

### 1️⃣ 단지 등록

**방법 1: 수동 등록**
1. `단지 목록` 탭 선택
2. 단지명과 단지 ID 입력
   - 단지 ID는 네이버 부동산 URL의 숫자 부분
   - 예: `https://new.land.naver.com/complexes/102378` → `102378`

**방법 2: URL 일괄 등록**
1. `URL등록` 버튼 클릭
2. 네이버 부동산 URL 여러 개 붙여넣기
3. 자동 파싱 후 일괄 등록

### 2️⃣ 조건 설정

1. **거래 유형 선택**: 매매 / 전세 / 월세
2. **필터 설정** (선택사항):
   - 가격 범위
   - 면적 범위
   - 층수 조건
   - 키워드 포함/제외

### 3️⃣ 크롤링 실행

1. `▶️ 크롤링 시작` 버튼 클릭 또는 `Ctrl+R`
2. 진행 상황 및 예상 남은 시간 확인
3. Toast 알림으로 완료 통지

### 4️⃣ 결과 확인 및 저장

- **테이블 확인**: 수집된 매물 목록 표시
- **더블 클릭**: 네이버 부동산 페이지로 이동
- **저장**: 
  - `Ctrl+S`: 엑셀(xlsx) 저장
  - `Ctrl+Shift+S`: CSV 저장
  - JSON 형식도 지원

---

## ⌨️ 단축키

| 기능 | 단축키 | 설명 |
|------|--------|------|
| **크롤링 시작** | `Ctrl+R` | 선택된 단지 매물 수집 시작 |
| **크롤링 중지** | `Ctrl+Shift+R` | 진행 중인 작업 중지 |  
| **Excel 저장** | `Ctrl+S` | 결과를 엑셀 파일로 저장 |
| **CSV 저장** | `Ctrl+Shift+S` | 결과를 CSV 파일로 저장 |
| **새로고침** | `F5` | 현재 탭 데이터 새로고침 |
| **검색** | `Ctrl+F` | 결과 내 검색 |
| **설정** | `Ctrl+,` | 설정 창 열기 |
| **테마 변경** | `Ctrl+T` | 다크/라이트 모드 전환 |
| **트레이 최소화** | `Ctrl+M` | 시스템 트레이로 숨기기 |
| **종료** | `Ctrl+Q` | 프로그램 종료 |

---

## 📂 파일 구조

프로그램 실행 시 자동 생성:

```
naverland-scrapper/
├── 부동산 매물 크롤러 v11.0.py    # 메인 프로그램
├── realestate_crawler.spec       # PyInstaller 빌드 파일
├── README.md                      # 이 파일
├── data/                          # 데이터 디렉토리
│   ├── complexes.db               # SQLite 데이터베이스
│   ├── settings.json              # 사용자 설정
│   ├── presets.json               # 필터 프리셋
│   └── search_history.json        # 검색 기록
└── logs/                          # 로그 디렉토리
    └── crawler_YYYYMMDD.log       # 날짜별 로그 파일
```

---

## 🎯 주요 기능 상세

### Toast 알림 시스템 (v11.0)

비침습적 알림으로 작업 상태를 직관적으로 확인:

- ✅ **Success**: 작업 완료, 파일 저장 완료 등
- ❌ **Error**: 오류 발생, 실패 알림
- ⚠️ **Warning**: 주의 필요 사항
- ℹ️ **Info**: 일반 정보 안내

Toast는 우측 하단에 표시되며 3초 후 자동으로 사라집니다.

### 가격 변동 추적

- 매물별 가격 변동 이력 저장
- 가격 상승/하락 시 📈/📉 아이콘 표시
- 그래프로 가격 추이 시각화

### 고급 필터링

결과 내에서 다양한 조건으로 필터:
- 가격 범위
- 면적 범위
- 층수 (저층/중층/고층)
- 키워드 포함/제외
- 신규 매물만 보기
- 가격 하락/변동 매물만 보기

---

## ⚠️ 주의사항

1. **개인 학습용**: 이 프로그램은 개인적인 학습 및 편의를 위해 제작되었습니다.
2. **크롤링 속도**: 과도한 속도는 접속 차단 위험이 있으므로 '보통' 또는 '느림' 권장
3. **데이터 이용**: 수집된 데이터의 상업적 이용에 대한 책임은 사용자에게 있습니다.
4. **Chrome 필수**: undetected-chromedriver 라이브러리 사용을 위해 Chrome 브라우저 필요

---

## 🔧 문제 해결

### 크롤러가 시작되지 않을 때

1. Chrome 브라우저 최신 버전 확인
2. 라이브러리 재설치: `pip install --upgrade undetected-chromedriver`
3. logs 폴더의 로그 파일 확인

### 데이터베이스 오류 발생 시

1. `data/complexes.db` 파일 백업
2. 프로그램 재시작 (자동으로 DB 재생성)
3. 필요시 DB 백업에서 복원 (설정 → DB 복원)

### HiDPI 디스플레이에서 UI가 흐릿할 때

v11.0에서 자동으로 HiDPI를 지원합니다. 문제가 계속되면:
1. Windows 디스플레이 배율 설정 확인
2. 프로그램 재시작

---

## 📝 버전 히스토리

- **v11.0** (2025-12-21): 전면 리팩토링, HiDPI 지원, Toast 알림, 코드 품질 개선
- **v10.5** (2025-12): UI 테마 개선, 자동 로그 정리, 성능 최적화
- **v10.0** (2025-12): 가격 변동 그래프, 버그 수정
- **v7.3** (2025): 가격 변동 추적, 신규 매물 배지, 고급 필터, URL 일괄 등록
- **v7.2** (2025): DB 안정성 개선
- **v7.1** (2025): 결과 요약 카드, 예상 시간 표시

---

## 📧 지원 및 피드백

문제가 발생하거나 기능 제안이 있으시면 logs 폴더의 로그 파일과 함께 문의해주세요.

**Happy Crawling! 🏠📊**
